# MLIR-AIR Programming Examples

These programming examples demonstrate how to leverage the AIR design flow with mlir-air Python bindings and the mlir-air intermediate representation (IR) to build applications targeting AI Engines on AMD NPUs.

## Operator Dashboard

See the **[Operator Dashboard](https://xilinx.github.io/mlir-air/programming_examples)** for the full table of supported operators with NPU1/NPU2 status indicators. The dashboard is auto-generated from LIT test files and published to GitHub Pages on every push to `main`.

## Getting Started

See the top-level [README](../README.md) for environment setup and build instructions. Once your environment is configured:

```bash
# Example: run matrix multiplication (bf16, 4x4 herd, 512x512x512)
cd matrix_multiplication/bf16
make run4x4

# Print generated MLIR without running
make print
```

Most examples with a `Makefile` support `make run` (compile and execute on hardware) and `make print` (generate MLIR only). Examples without a Makefile can be run directly with Python:

```bash
python3 run.py                    # compile and run (XRTRunner)
python3 run.py --print-module-only  # print IR only
```

## Benchmarking

The [matrix multiplication](matrix_multiplication/) examples include sweep infrastructure for measuring end-to-end latency across problem sizes:

```bash
cd matrix_multiplication/bf16
make sweep4x4    # sweep problem sizes 256-2048 with a 4x4 herd
make profile     # profile a single 1024^3 problem on hardware
```

Sweep results are saved as CSV files for analysis. See the [bf16 README](matrix_multiplication/bf16/README.md) for details on tile size configuration and architecture selection.
